{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 11.4MB 3.8MB/s eta 0:00:01\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-1.9.6\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.DeepCNNModel import DeepCNNModel\n",
    "from models.RandomModel import RandomModel\n",
    "from train_cnn import train_deepcnn_model\n",
    "import fsutils as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "FRAME_SKIP = 4\n",
    "UPDATE_FREQ = FRAME_SKIP\n",
    "TARGET_NET_SYNC_FREQ = 1000\n",
    "MAX_EPS = 250\n",
    "MAX_STEPS_PER_EP = 1000\n",
    "\n",
    "# CNN hyperparams\n",
    "TAU = 4\n",
    "GAMMA = 0.95\n",
    "EPS_START = 0.25\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY_WINDOW = 50\n",
    "REPLAY_BUF_CAPACITY = 10000\n",
    "REPLAY_BUF_PREFILL_AMT = 5000\n",
    "LR = 0.001\n",
    "DOWNSAMPLE_SIZE = (112, 112)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_ADVERSARIES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = DeepCNNModel(tau=TAU, gamma=GAMMA, eps_start=EPS_START, eps_end=EPS_END,\n",
    "                            eps_decay_window=EPS_DECAY_WINDOW, replay_buf_capacity=REPLAY_BUF_CAPACITY,\n",
    "                            replay_buf_prefill_amt=REPLAY_BUF_PREFILL_AMT, lr=LR,\n",
    "                            downsample_size=DOWNSAMPLE_SIZE, batch_size=BATCH_SIZE)\n",
    "cnn_model_name = 'dqn_cnn_with_enemies_first250ep'\n",
    "\n",
    "# loading trained model but getting rid of replay buf (which doesn't have enemies)\n",
    "saved_net = fs.load_net_from_device(cnn_model.net, 'dqn_cnn_500ep_v2', 'cpu')\n",
    "cnn_model.net = saved_net\n",
    "cnn_model.sync_target_net()\n",
    "\n",
    "adversary_models = []\n",
    "for i in range(NUM_ADVERSARIES):\n",
    "    adversary_models.append(RandomModel(min_steps=5, max_steps=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling replay buffer to 50.0% capacity...\n",
      "Replay buffer filled with 5000 samples!\n",
      "Beginning training...\n",
      "=== Starting Episode 0 ===\n",
      "Step 0\n",
      "Mean Episode Loss: 0.0133 | Episode Reward: -99.3241 | Mean Reward: -99.3241\n",
      "Model has been training for 17.5427 minutes.\n",
      "=== Starting Episode 1 ===\n",
      "Step 250\n",
      "Step 500\n",
      "Step 750\n",
      "Step 1000\n",
      "Mean Episode Loss: 2.3567 | Episode Reward: 66.0690 | Mean Reward: -16.6275\n",
      "Model has been training for 22.9179 minutes.\n",
      "=== Starting Episode 2 ===\n",
      "Step 1250\n",
      "Step 1500\n",
      "Step 1750\n",
      "Step 2000\n",
      "Mean Episode Loss: 3.0372 | Episode Reward: 25.9716 | Mean Reward: -2.4278\n",
      "Model has been training for 28.0182 minutes.\n",
      "=== Starting Episode 3 ===\n",
      "Step 2250\n",
      "Step 2500\n",
      "Step 2750\n",
      "Step 3000\n",
      "Mean Episode Loss: 1.3011 | Episode Reward: 29.4748 | Mean Reward: 5.5478\n",
      "Model has been training for 32.9982 minutes.\n",
      "=== Starting Episode 4 ===\n",
      "Step 3250\n",
      "Step 3500\n",
      "Step 3750\n",
      "Step 4000\n",
      "Mean Episode Loss: 0.0341 | Episode Reward: 159.2683 | Mean Reward: 36.2919\n",
      "Model has been training for 38.0665 minutes.\n",
      "=== Starting Episode 5 ===\n",
      "Mean Episode Loss: 0.0361 | Episode Reward: -90.9021 | Mean Reward: 15.0929\n",
      "Model has been training for 38.7097 minutes.\n",
      "=== Starting Episode 6 ===\n",
      "Step 4250\n",
      "Step 4500\n",
      "Step 4750\n",
      "Step 5000\n",
      "Mean Episode Loss: 2.5784 | Episode Reward: 253.6152 | Mean Reward: 49.1675\n",
      "Model has been training for 43.7243 minutes.\n",
      "=== Starting Episode 7 ===\n",
      "Mean Episode Loss: 0.0461 | Episode Reward: -97.2158 | Mean Reward: 30.8696\n",
      "Model has been training for 43.9339 minutes.\n",
      "=== Starting Episode 8 ===\n",
      "Step 5250\n",
      "Step 5500\n",
      "Step 5750\n",
      "Step 6000\n",
      "Mean Episode Loss: 8.0257 | Episode Reward: 402.3806 | Mean Reward: 72.1486\n",
      "Model has been training for 48.9618 minutes.\n",
      "=== Starting Episode 9 ===\n",
      "Step 6250\n",
      "Step 6500\n",
      "Step 6750\n",
      "Step 7000\n",
      "Mean Episode Loss: 13.3055 | Episode Reward: 34.0700 | Mean Reward: 68.3408\n",
      "Model has been training for 53.4638 minutes.\n",
      "=== Starting Episode 10 ===\n",
      "Step 7250\n",
      "Mean Episode Loss: 11.6063 | Episode Reward: -96.8049 | Mean Reward: 68.5927\n",
      "Model has been training for 53.8774 minutes.\n",
      "=== Starting Episode 11 ===\n",
      "Step 7500\n",
      "Step 7750\n",
      "Step 8000\n",
      "Step 8250\n",
      "Mean Episode Loss: 15.3408 | Episode Reward: 388.0427 | Mean Reward: 100.7900\n",
      "Model has been training for 58.3090 minutes.\n",
      "=== Starting Episode 12 ===\n",
      "Step 8500\n",
      "Step 8750\n",
      "Step 9000\n",
      "Step 9250\n",
      "Mean Episode Loss: 15.1552 | Episode Reward: 212.3796 | Mean Reward: 119.4308\n",
      "Model has been training for 62.8425 minutes.\n",
      "=== Starting Episode 13 ===\n",
      "Step 9500\n",
      "Step 9750\n",
      "Step 10000\n",
      "Step 10250\n",
      "Mean Episode Loss: 8.4974 | Episode Reward: 35.0765 | Mean Reward: 119.9910\n",
      "Model has been training for 67.4050 minutes.\n",
      "=== Starting Episode 14 ===\n",
      "Mean Episode Loss: 0.3793 | Episode Reward: -100.0000 | Mean Reward: 94.0642\n",
      "Model has been training for 67.4159 minutes.\n",
      "=== Starting Episode 15 ===\n",
      "Step 10500\n",
      "Step 10750\n",
      "Step 11000\n",
      "Step 11250\n",
      "Mean Episode Loss: 9.6298 | Episode Reward: 43.0864 | Mean Reward: 107.4630\n",
      "Model has been training for 72.0503 minutes.\n",
      "=== Starting Episode 16 ===\n",
      "Step 11500\n",
      "Step 11750\n",
      "Step 12000\n",
      "Step 12250\n",
      "Mean Episode Loss: 10.1372 | Episode Reward: 13.0729 | Mean Reward: 83.4088\n",
      "Model has been training for 76.7494 minutes.\n",
      "=== Starting Episode 17 ===\n",
      "Step 12500\n",
      "Mean Episode Loss: 8.4132 | Episode Reward: -84.9314 | Mean Reward: 84.6372\n",
      "Model has been training for 78.6493 minutes.\n",
      "=== Starting Episode 18 ===\n",
      "Step 12750\n",
      "Step 13000\n",
      "Step 13250\n",
      "Step 13500\n",
      "Mean Episode Loss: 5.3833 | Episode Reward: 23.8728 | Mean Reward: 46.7864\n",
      "Model has been training for 83.3563 minutes.\n",
      "=== Starting Episode 19 ===\n",
      "Step 13750\n",
      "Mean Episode Loss: 11.2383 | Episode Reward: -94.9845 | Mean Reward: 33.8810\n",
      "Model has been training for 84.7180 minutes.\n",
      "=== Starting Episode 20 ===\n",
      "Step 14000\n",
      "Step 14250\n",
      "Step 14500\n",
      "Step 14750\n",
      "Mean Episode Loss: 7.4080 | Episode Reward: 23.7988 | Mean Reward: 45.9414\n",
      "Model has been training for 89.3315 minutes.\n",
      "=== Starting Episode 21 ===\n",
      "Step 15000\n",
      "Step 15250\n",
      "Step 15500\n",
      "Step 15750\n",
      "Mean Episode Loss: 4.0901 | Episode Reward: 320.7290 | Mean Reward: 39.2100\n",
      "Model has been training for 94.1041 minutes.\n",
      "=== Starting Episode 22 ===\n",
      "Step 16000\n",
      "Step 16250\n",
      "Step 16500\n",
      "Step 16750\n",
      "Mean Episode Loss: 12.9039 | Episode Reward: -3.5678 | Mean Reward: 17.6153\n",
      "Model has been training for 98.8218 minutes.\n",
      "=== Starting Episode 23 ===\n",
      "Step 17000\n",
      "Step 17250\n",
      "Step 17500\n",
      "Step 17750\n",
      "Mean Episode Loss: 5.8690 | Episode Reward: 112.7297 | Mean Reward: 25.3806\n",
      "Model has been training for 103.4870 minutes.\n",
      "=== Starting Episode 24 ===\n",
      "Step 18000\n",
      "Step 18250\n",
      "Step 18500\n",
      "Step 18750\n",
      "Mean Episode Loss: 5.7663 | Episode Reward: 10.0746 | Mean Reward: 36.3880\n",
      "Model has been training for 108.1521 minutes.\n",
      "=== Starting Episode 25 ===\n",
      "Step 19000\n",
      "Mean Episode Loss: 16.9207 | Episode Reward: -96.0616 | Mean Reward: 22.4732\n",
      "Model has been training for 108.6240 minutes.\n",
      "=== Starting Episode 26 ===\n",
      "Step 19250\n",
      "Step 19500\n",
      "Step 19750\n",
      "Step 20000\n",
      "Mean Episode Loss: 6.6497 | Episode Reward: 9.0641 | Mean Reward: 22.0724\n",
      "Model has been training for 113.4667 minutes.\n",
      "=== Starting Episode 27 ===\n",
      "Mean Episode Loss: 1.4491 | Episode Reward: -97.0924 | Mean Reward: 20.8563\n",
      "Model has been training for 114.0974 minutes.\n",
      "=== Starting Episode 28 ===\n",
      "Step 20250\n",
      "Step 20500\n",
      "Step 20750\n",
      "Step 21000\n",
      "Mean Episode Loss: 5.7600 | Episode Reward: 289.7400 | Mean Reward: 47.4430\n",
      "Model has been training for 118.7125 minutes.\n",
      "=== Starting Episode 29 ===\n",
      "Step 21250\n",
      "Step 21500\n",
      "Step 21750\n",
      "Step 22000\n",
      "Mean Episode Loss: 8.5368 | Episode Reward: 5.0664 | Mean Reward: 57.4481\n",
      "Model has been training for 123.9405 minutes.\n",
      "=== Starting Episode 30 ===\n",
      "Step 22250\n",
      "Step 22500\n",
      "Step 22750\n",
      "Step 23000\n",
      "Mean Episode Loss: 6.3810 | Episode Reward: 91.5502 | Mean Reward: 64.2232\n",
      "Model has been training for 129.0691 minutes.\n",
      "=== Starting Episode 31 ===\n",
      "Step 23250\n",
      "Step 23500\n",
      "Step 23750\n",
      "Step 24000\n",
      "Mean Episode Loss: 4.4191 | Episode Reward: 318.7046 | Mean Reward: 64.0208\n",
      "Model has been training for 134.2911 minutes.\n",
      "=== Starting Episode 32 ===\n",
      "Step 24250\n",
      "Step 24500\n",
      "Step 24750\n",
      "Step 25000\n",
      "Mean Episode Loss: 4.7679 | Episode Reward: 22.1776 | Mean Reward: 66.5953\n",
      "Model has been training for 139.5276 minutes.\n",
      "=== Starting Episode 33 ===\n",
      "Step 25250\n",
      "Step 25500\n",
      "Mean Episode Loss: 3.5851 | Episode Reward: -98.4816 | Mean Reward: 45.4742\n",
      "Model has been training for 141.5596 minutes.\n",
      "=== Starting Episode 34 ===\n",
      "Mean Episode Loss: 24.0406 | Episode Reward: -93.9027 | Mean Reward: 35.0765\n",
      "Model has been training for 142.2329 minutes.\n",
      "=== Starting Episode 35 ===\n",
      "Step 25750\n",
      "Step 26000\n",
      "Step 26250\n",
      "Step 26500\n",
      "Mean Episode Loss: 12.0339 | Episode Reward: 184.6753 | Mean Reward: 63.1501\n",
      "Model has been training for 147.3904 minutes.\n",
      "=== Starting Episode 36 ===\n",
      "Step 26750\n",
      "Step 27000\n",
      "Step 27250\n",
      "Step 27500\n",
      "Mean Episode Loss: 4.6676 | Episode Reward: 23.4623 | Mean Reward: 64.5900\n",
      "Model has been training for 152.4338 minutes.\n",
      "=== Starting Episode 37 ===\n",
      "Step 27750\n",
      "Step 28000\n",
      "Step 28250\n",
      "Step 28500\n",
      "Mean Episode Loss: 11.6942 | Episode Reward: 207.7087 | Mean Reward: 95.0701\n",
      "Model has been training for 157.5912 minutes.\n",
      "=== Starting Episode 38 ===\n",
      "Step 28750\n",
      "Step 29000\n",
      "Step 29250\n",
      "Step 29500\n",
      "Mean Episode Loss: 8.4307 | Episode Reward: 7.6541 | Mean Reward: 66.8615\n",
      "Model has been training for 162.7337 minutes.\n",
      "=== Starting Episode 39 ===\n",
      "Step 29750\n",
      "Step 30000\n",
      "Step 30250\n",
      "Step 30500\n",
      "Mean Episode Loss: 5.3045 | Episode Reward: 10.9068 | Mean Reward: 67.4455\n",
      "Model has been training for 167.9459 minutes.\n",
      "=== Starting Episode 40 ===\n",
      "Step 30750\n",
      "Step 31000\n",
      "Step 31250\n",
      "Step 31500\n",
      "Mean Episode Loss: 5.3633 | Episode Reward: 74.4363 | Mean Reward: 65.7342\n",
      "Model has been training for 172.9462 minutes.\n",
      "=== Starting Episode 41 ===\n",
      "Step 31750\n",
      "Mean Episode Loss: 8.4153 | Episode Reward: -100.0000 | Mean Reward: 23.8637\n",
      "Model has been training for 172.9576 minutes.\n",
      "=== Starting Episode 42 ===\n",
      "Step 32000\n",
      "Step 32250\n",
      "Step 32500\n",
      "Step 32750\n",
      "Mean Episode Loss: 7.4140 | Episode Reward: 22.1890 | Mean Reward: 23.8648\n",
      "Model has been training for 178.0605 minutes.\n",
      "=== Starting Episode 43 ===\n",
      "Step 33000\n",
      "Step 33250\n",
      "Step 33500\n",
      "Step 33750\n",
      "Mean Episode Loss: 7.1031 | Episode Reward: 20.1552 | Mean Reward: 35.7285\n",
      "Model has been training for 183.0918 minutes.\n",
      "=== Starting Episode 44 ===\n",
      "Step 34000\n",
      "Step 34250\n",
      "Step 34500\n",
      "Step 34750\n",
      "Mean Episode Loss: 8.3733 | Episode Reward: 546.6944 | Mean Reward: 99.7882\n",
      "Model has been training for 187.9332 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Episode 45 ===\n",
      "Step 35000\n",
      "Step 35250\n",
      "Mean Episode Loss: 2.6512 | Episode Reward: -88.8509 | Mean Reward: 72.4356\n",
      "Model has been training for 190.5098 minutes.\n",
      "=== Starting Episode 46 ===\n",
      "Step 35500\n",
      "Mean Episode Loss: 9.3712 | Episode Reward: -87.6470 | Mean Reward: 61.3247\n",
      "Model has been training for 192.0613 minutes.\n",
      "=== Starting Episode 47 ===\n",
      "Step 35750\n",
      "Step 36000\n",
      "Step 36250\n",
      "Step 36500\n",
      "Mean Episode Loss: 9.9446 | Episode Reward: -2.2162 | Mean Reward: 40.3322\n",
      "Model has been training for 196.6267 minutes.\n",
      "=== Starting Episode 48 ===\n",
      "Step 36750\n",
      "Step 37000\n",
      "Step 37250\n",
      "Step 37500\n",
      "Mean Episode Loss: 16.1863 | Episode Reward: 298.0953 | Mean Reward: 69.3763\n",
      "Model has been training for 201.3933 minutes.\n",
      "=== Starting Episode 49 ===\n",
      "Mean Episode Loss: 1.8379 | Episode Reward: -98.2074 | Mean Reward: 58.4649\n",
      "Model has been training for 201.5367 minutes.\n",
      "=== Starting Episode 50 ===\n",
      "Step 37750\n",
      "Step 38000\n",
      "Step 38250\n",
      "Step 38500\n",
      "Mean Episode Loss: 15.0365 | Episode Reward: 23.6597 | Mean Reward: 53.3872\n",
      "Model has been training for 206.2294 minutes.\n",
      "=== Starting Episode 51 ===\n",
      "Step 38750\n",
      "Step 39000\n",
      "Step 39250\n",
      "Step 39500\n",
      "Mean Episode Loss: 7.4349 | Episode Reward: -54.8045 | Mean Reward: 57.9067\n",
      "Model has been training for 210.8190 minutes.\n",
      "=== Starting Episode 52 ===\n",
      "Step 39750\n",
      "Mean Episode Loss: 10.2182 | Episode Reward: -95.0455 | Mean Reward: 46.1833\n",
      "Model has been training for 211.5213 minutes.\n",
      "=== Starting Episode 53 ===\n",
      "Step 40000\n",
      "Step 40250\n",
      "Step 40500\n",
      "Step 40750\n",
      "Mean Episode Loss: 13.0389 | Episode Reward: -59.4651 | Mean Reward: 38.2213\n",
      "Model has been training for 216.3503 minutes.\n",
      "=== Starting Episode 54 ===\n",
      "Step 41000\n",
      "Mean Episode Loss: 10.0275 | Episode Reward: -92.2289 | Mean Reward: -25.6711\n",
      "Model has been training for 218.1563 minutes.\n",
      "=== Starting Episode 55 ===\n",
      "Step 41250\n",
      "Step 41500\n",
      "Step 41750\n",
      "Step 42000\n",
      "Mean Episode Loss: 10.4469 | Episode Reward: 32.0549 | Mean Reward: -13.5805\n",
      "Model has been training for 223.2143 minutes.\n",
      "=== Starting Episode 56 ===\n",
      "Step 42250\n",
      "Step 42500\n",
      "Step 42750\n",
      "Mean Episode Loss: 12.9901 | Episode Reward: -97.0602 | Mean Reward: -14.5218\n",
      "Model has been training for 225.8142 minutes.\n",
      "=== Starting Episode 57 ===\n",
      "Step 43000\n",
      "Step 43250\n",
      "Step 43500\n",
      "Step 43750\n",
      "Mean Episode Loss: 15.3231 | Episode Reward: 17.9938 | Mean Reward: -12.5008\n",
      "Model has been training for 230.9440 minutes.\n",
      "=== Starting Episode 58 ===\n",
      "Step 44000\n",
      "Step 44250\n",
      "Step 44500\n",
      "Step 44750\n",
      "Mean Episode Loss: 9.2202 | Episode Reward: 254.8830 | Mean Reward: -16.8220\n",
      "Model has been training for 236.2021 minutes.\n",
      "=== Starting Episode 59 ===\n",
      "Step 45000\n",
      "Step 45250\n",
      "Step 45500\n",
      "Step 45750\n",
      "Mean Episode Loss: 19.2729 | Episode Reward: 243.2293 | Mean Reward: 17.3216\n",
      "Model has been training for 241.4190 minutes.\n",
      "=== Starting Episode 60 ===\n",
      "Step 46000\n",
      "Step 46250\n",
      "Step 46500\n",
      "Step 46750\n",
      "Mean Episode Loss: 8.9098 | Episode Reward: 256.6338 | Mean Reward: 40.6190\n",
      "Model has been training for 245.9541 minutes.\n",
      "=== Starting Episode 61 ===\n",
      "Step 47000\n",
      "Step 47250\n",
      "Step 47500\n",
      "Step 47750\n",
      "Mean Episode Loss: 15.9468 | Episode Reward: 210.6830 | Mean Reward: 67.1678\n",
      "Model has been training for 250.1165 minutes.\n",
      "=== Starting Episode 62 ===\n",
      "Step 48000\n",
      "Step 48250\n",
      "Step 48500\n",
      "Step 48750\n",
      "Mean Episode Loss: 8.8139 | Episode Reward: -1.0444 | Mean Reward: 76.5679\n",
      "Model has been training for 254.4713 minutes.\n",
      "=== Starting Episode 63 ===\n",
      "Step 49000\n",
      "Step 49250\n",
      "Mean Episode Loss: 6.8479 | Episode Reward: -181.9072 | Mean Reward: 64.3237\n",
      "Model has been training for 257.6480 minutes.\n",
      "=== Starting Episode 64 ===\n",
      "Step 49500\n",
      "Step 49750\n",
      "Step 50000\n",
      "Step 50250\n",
      "Mean Episode Loss: 14.3929 | Episode Reward: 220.8465 | Mean Reward: 95.6312\n",
      "Model has been training for 262.5655 minutes.\n",
      "=== Starting Episode 65 ===\n",
      "Step 50500\n",
      "Mean Episode Loss: 0.8693 | Episode Reward: -99.1150 | Mean Reward: 82.5143\n",
      "Model has been training for 262.6827 minutes.\n",
      "=== Starting Episode 66 ===\n",
      "Step 50750\n",
      "Step 51000\n",
      "Step 51250\n",
      "Step 51500\n",
      "Mean Episode Loss: 9.0906 | Episode Reward: 130.1551 | Mean Reward: 105.2358\n",
      "Model has been training for 267.7676 minutes.\n",
      "=== Starting Episode 67 ===\n",
      "Mean Episode Loss: 0.9722 | Episode Reward: -99.0816 | Mean Reward: 93.5283\n",
      "Model has been training for 267.8428 minutes.\n",
      "=== Starting Episode 68 ===\n",
      "Step 51750\n",
      "Step 52000\n",
      "Step 52250\n",
      "Step 52500\n",
      "Mean Episode Loss: 11.5849 | Episode Reward: 5.0109 | Mean Reward: 68.5410\n",
      "Model has been training for 273.2182 minutes.\n",
      "=== Starting Episode 69 ===\n",
      "Step 52750\n",
      "Step 53000\n",
      "Step 53250\n",
      "Step 53500\n",
      "Mean Episode Loss: 11.6311 | Episode Reward: 0.8064 | Mean Reward: 44.2988\n",
      "Model has been training for 278.4769 minutes.\n",
      "=== Starting Episode 70 ===\n",
      "Step 53750\n",
      "Step 54000\n",
      "Step 54250\n",
      "Step 54500\n",
      "Mean Episode Loss: 12.5115 | Episode Reward: 14.2456 | Mean Reward: 20.0599\n",
      "Model has been training for 283.7581 minutes.\n",
      "=== Starting Episode 71 ===\n",
      "Step 54750\n",
      "Step 55000\n",
      "Step 55250\n",
      "Step 55500\n",
      "Mean Episode Loss: 17.9773 | Episode Reward: 1.6469 | Mean Reward: -0.8437\n",
      "Model has been training for 289.1506 minutes.\n",
      "=== Starting Episode 72 ===\n",
      "Step 55750\n",
      "Step 56000\n",
      "Step 56250\n",
      "Step 56500\n",
      "Mean Episode Loss: 6.0890 | Episode Reward: 317.1872 | Mean Reward: 30.9795\n",
      "Model has been training for 294.4803 minutes.\n",
      "=== Starting Episode 73 ===\n",
      "Step 56750\n",
      "Step 57000\n",
      "Step 57250\n",
      "Step 57500\n",
      "Mean Episode Loss: 8.1625 | Episode Reward: 3.9169 | Mean Reward: 49.5619\n",
      "Model has been training for 299.5574 minutes.\n",
      "=== Starting Episode 74 ===\n",
      "Step 57750\n",
      "Step 58000\n",
      "Step 58250\n",
      "Step 58500\n",
      "Mean Episode Loss: 4.8620 | Episode Reward: 17.1895 | Mean Reward: 29.1962\n",
      "Model has been training for 304.7131 minutes.\n",
      "=== Starting Episode 75 ===\n",
      "Step 58750\n",
      "Step 59000\n",
      "Step 59250\n",
      "Step 59500\n",
      "Mean Episode Loss: 6.5288 | Episode Reward: 6.0878 | Mean Reward: 39.7165\n",
      "Model has been training for 309.3994 minutes.\n",
      "=== Starting Episode 76 ===\n",
      "Step 59750\n",
      "Step 60000\n",
      "Step 60250\n",
      "Step 60500\n",
      "Mean Episode Loss: 6.7768 | Episode Reward: 72.2830 | Mean Reward: 33.9293\n",
      "Model has been training for 314.0927 minutes.\n",
      "=== Starting Episode 77 ===\n",
      "Mean Episode Loss: 3.3745 | Episode Reward: -95.0143 | Mean Reward: 34.3360\n",
      "Model has been training for 314.7056 minutes.\n",
      "=== Starting Episode 78 ===\n",
      "Step 60750\n",
      "Step 61000\n",
      "Mean Episode Loss: 11.0403 | Episode Reward: -85.1351 | Mean Reward: 25.3214\n",
      "Model has been training for 316.8253 minutes.\n",
      "=== Starting Episode 79 ===\n",
      "Step 61250\n",
      "Mean Episode Loss: 10.1352 | Episode Reward: -96.3735 | Mean Reward: 15.6034\n",
      "Model has been training for 317.9753 minutes.\n",
      "=== Starting Episode 80 ===\n",
      "Step 61500\n",
      "Step 61750\n",
      "Step 62000\n",
      "Step 62250\n",
      "Mean Episode Loss: 7.6215 | Episode Reward: -1.1490 | Mean Reward: 14.0639\n",
      "Model has been training for 323.0357 minutes.\n",
      "=== Starting Episode 81 ===\n",
      "Mean Episode Loss: 0.4940 | Episode Reward: -94.5979 | Mean Reward: 4.4395\n",
      "Model has been training for 323.5188 minutes.\n",
      "=== Starting Episode 82 ===\n",
      "Step 62500\n",
      "Step 62750\n",
      "Mean Episode Loss: 8.5013 | Episode Reward: -98.7669 | Mean Reward: -37.1559\n",
      "Model has been training for 325.8662 minutes.\n",
      "=== Starting Episode 83 ===\n",
      "Step 63000\n",
      "Step 63250\n",
      "Step 63500\n",
      "Step 63750\n",
      "Mean Episode Loss: 5.9973 | Episode Reward: 8.2070 | Mean Reward: -36.7269\n",
      "Model has been training for 331.0885 minutes.\n",
      "=== Starting Episode 84 ===\n",
      "Mean Episode Loss: 9.5358 | Episode Reward: -88.3904 | Mean Reward: -47.2849\n",
      "Model has been training for 331.8303 minutes.\n",
      "=== Starting Episode 85 ===\n",
      "Step 64000\n",
      "Step 64250\n",
      "Step 64500\n",
      "Step 64750\n",
      "Mean Episode Loss: 8.5248 | Episode Reward: 143.6539 | Mean Reward: -33.5283\n",
      "Model has been training for 337.2098 minutes.\n",
      "=== Starting Episode 86 ===\n",
      "Step 65000\n",
      "Step 65250\n",
      "Step 65500\n",
      "Step 65750\n",
      "Mean Episode Loss: 13.0710 | Episode Reward: -0.6505 | Mean Reward: -40.8217\n",
      "Model has been training for 342.3786 minutes.\n",
      "=== Starting Episode 87 ===\n",
      "Step 66000\n",
      "Step 66250\n",
      "Step 66500\n",
      "Step 66750\n",
      "Mean Episode Loss: 6.3344 | Episode Reward: 10.4680 | Mean Reward: -30.2734\n",
      "Model has been training for 347.5589 minutes.\n",
      "=== Starting Episode 88 ===\n",
      "Step 67000\n",
      "Step 67250\n",
      "Mean Episode Loss: 1.4456 | Episode Reward: -89.4930 | Mean Reward: -30.7092\n",
      "Model has been training for 349.7021 minutes.\n",
      "=== Starting Episode 89 ===\n",
      "Step 67500\n",
      "Step 67750\n",
      "Step 68000\n",
      "Step 68250\n",
      "Mean Episode Loss: 4.7736 | Episode Reward: 30.3071 | Mean Reward: -18.0412\n",
      "Model has been training for 354.3350 minutes.\n",
      "=== Starting Episode 90 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 68500\n",
      "Step 68750\n",
      "Step 69000\n",
      "Step 69250\n",
      "Mean Episode Loss: 4.7903 | Episode Reward: 14.9132 | Mean Reward: -16.4349\n",
      "Model has been training for 359.1634 minutes.\n",
      "=== Starting Episode 91 ===\n",
      "Step 69500\n",
      "Step 69750\n",
      "Step 70000\n",
      "Step 70250\n",
      "Mean Episode Loss: 3.7699 | Episode Reward: 55.3287 | Mean Reward: -1.4423\n",
      "Model has been training for 364.1493 minutes.\n",
      "=== Starting Episode 92 ===\n",
      "Step 70500\n",
      "Step 70750\n",
      "Step 71000\n",
      "Step 71250\n",
      "Mean Episode Loss: 4.8998 | Episode Reward: 4.0549 | Mean Reward: 8.8399\n",
      "Model has been training for 368.8758 minutes.\n",
      "=== Starting Episode 93 ===\n",
      "Step 71500\n",
      "Step 71750\n",
      "Step 72000\n",
      "Step 72250\n",
      "Mean Episode Loss: 2.2200 | Episode Reward: 28.1175 | Mean Reward: 10.8309\n",
      "Model has been training for 373.7542 minutes.\n",
      "=== Starting Episode 94 ===\n",
      "Step 72500\n",
      "Mean Episode Loss: 11.0329 | Episode Reward: -98.9048 | Mean Reward: 9.7795\n",
      "Model has been training for 374.5264 minutes.\n",
      "=== Starting Episode 95 ===\n",
      "Step 72750\n",
      "Step 73000\n",
      "Mean Episode Loss: 6.6710 | Episode Reward: -189.7108 | Mean Reward: -23.5570\n",
      "Model has been training for 377.3100 minutes.\n",
      "=== Starting Episode 96 ===\n",
      "Step 73250\n",
      "Step 73500\n",
      "Step 73750\n",
      "Step 74000\n",
      "Mean Episode Loss: 10.2923 | Episode Reward: 74.4065 | Mean Reward: -16.0513\n",
      "Model has been training for 382.3032 minutes.\n",
      "=== Starting Episode 97 ===\n",
      "Step 74250\n",
      "Step 74500\n",
      "Step 74750\n",
      "Step 75000\n",
      "Mean Episode Loss: 6.4786 | Episode Reward: 24.0695 | Mean Reward: -14.6911\n",
      "Model has been training for 387.0971 minutes.\n",
      "=== Starting Episode 98 ===\n",
      "Step 75250\n",
      "Step 75500\n",
      "Step 75750\n",
      "Step 76000\n",
      "Mean Episode Loss: 5.6173 | Episode Reward: 3.8870 | Mean Reward: -5.3531\n",
      "Model has been training for 391.8533 minutes.\n",
      "=== Starting Episode 99 ===\n",
      "Step 76250\n",
      "Step 76500\n",
      "Step 76750\n",
      "Step 77000\n",
      "Mean Episode Loss: 8.9799 | Episode Reward: 8.5917 | Mean Reward: -7.5247\n",
      "Model has been training for 396.9094 minutes.\n",
      "=== Starting Episode 100 ===\n",
      "Step 77250\n",
      "Step 77500\n",
      "Step 77750\n",
      "Step 78000\n",
      "Mean Episode Loss: 5.9261 | Episode Reward: 99.1476 | Mean Reward: 0.8988\n",
      "Model has been training for 401.7192 minutes.\n",
      "=== Starting Episode 101 ===\n",
      "Step 78250\n",
      "Step 78500\n",
      "Step 78750\n",
      "Step 79000\n",
      "Mean Episode Loss: 5.7025 | Episode Reward: 8.1253 | Mean Reward: -3.8216\n",
      "Model has been training for 406.0093 minutes.\n",
      "=== Starting Episode 102 ===\n",
      "Step 79250\n",
      "Step 79500\n",
      "Step 79750\n",
      "Step 80000\n",
      "Mean Episode Loss: 8.8245 | Episode Reward: 35.4735 | Mean Reward: -0.6797\n",
      "Model has been training for 410.9098 minutes.\n",
      "=== Starting Episode 103 ===\n",
      "Step 80250\n",
      "Step 80500\n",
      "Step 80750\n",
      "Step 81000\n",
      "Mean Episode Loss: 6.5655 | Episode Reward: 8.5417 | Mean Reward: -2.6373\n",
      "Model has been training for 415.2414 minutes.\n",
      "=== Starting Episode 104 ===\n",
      "Mean Episode Loss: 0.3561 | Episode Reward: -100.0432 | Mean Reward: -2.7511\n",
      "Model has been training for 415.2895 minutes.\n",
      "=== Starting Episode 105 ===\n",
      "Step 81250\n",
      "Step 81500\n",
      "Step 81750\n",
      "Step 82000\n",
      "Mean Episode Loss: 3.3845 | Episode Reward: 78.5837 | Mean Reward: 24.0783\n",
      "Model has been training for 419.6277 minutes.\n",
      "=== Starting Episode 106 ===\n",
      "Step 82250\n",
      "Step 82500\n",
      "Step 82750\n",
      "Step 83000\n",
      "Mean Episode Loss: 3.5400 | Episode Reward: 17.1088 | Mean Reward: 18.3486\n",
      "Model has been training for 424.1567 minutes.\n",
      "=== Starting Episode 107 ===\n",
      "Step 83250\n",
      "Mean Episode Loss: 2.5341 | Episode Reward: -94.7415 | Mean Reward: 6.4675\n",
      "Model has been training for 424.6839 minutes.\n",
      "=== Starting Episode 108 ===\n",
      "Step 83500\n",
      "Step 83750\n",
      "Step 84000\n",
      "Step 84250\n",
      "Mean Episode Loss: 12.1514 | Episode Reward: 270.0734 | Mean Reward: 33.0861\n",
      "Model has been training for 429.0695 minutes.\n",
      "=== Starting Episode 109 ===\n",
      "Step 84500\n",
      "Step 84750\n",
      "Step 85000\n",
      "Step 85250\n",
      "Mean Episode Loss: 6.9679 | Episode Reward: -2.4595 | Mean Reward: 31.9810\n",
      "Model has been training for 433.4840 minutes.\n",
      "=== Starting Episode 110 ===\n",
      "Step 85500\n",
      "Step 85750\n",
      "Mean Episode Loss: 2.8235 | Episode Reward: -90.4855 | Mean Reward: 13.0177\n",
      "Model has been training for 436.2408 minutes.\n",
      "=== Starting Episode 111 ===\n",
      "Step 86000\n",
      "Step 86250\n",
      "Step 86500\n",
      "Step 86750\n",
      "Mean Episode Loss: 11.7326 | Episode Reward: 7.9783 | Mean Reward: 13.0030\n",
      "Model has been training for 440.6728 minutes.\n",
      "=== Starting Episode 112 ===\n",
      "Step 87000\n",
      "Step 87250\n",
      "Step 87500\n",
      "Step 87750\n",
      "Mean Episode Loss: 3.1366 | Episode Reward: 1.8152 | Mean Reward: 9.6372\n",
      "Model has been training for 445.2502 minutes.\n",
      "=== Starting Episode 113 ===\n",
      "Step 88000\n",
      "Step 88250\n",
      "Step 88500\n",
      "Step 88750\n",
      "Mean Episode Loss: 7.5787 | Episode Reward: 12.0920 | Mean Reward: 9.9922\n",
      "Model has been training for 449.6742 minutes.\n",
      "=== Starting Episode 114 ===\n",
      "Step 89000\n",
      "Step 89250\n",
      "Step 89500\n",
      "Mean Episode Loss: 5.6507 | Episode Reward: -103.9411 | Mean Reward: 9.6024\n",
      "Model has been training for 452.4419 minutes.\n",
      "=== Starting Episode 115 ===\n",
      "Step 89750\n",
      "Step 90000\n",
      "Step 90250\n",
      "Step 90500\n",
      "Mean Episode Loss: 8.2019 | Episode Reward: -0.5683 | Mean Reward: 1.6872\n",
      "Model has been training for 456.8581 minutes.\n",
      "=== Starting Episode 116 ===\n",
      "Step 90750\n",
      "Step 91000\n",
      "Step 91250\n",
      "Step 91500\n",
      "Mean Episode Loss: 7.0454 | Episode Reward: 6.7068 | Mean Reward: 0.6470\n",
      "Model has been training for 461.6660 minutes.\n",
      "=== Starting Episode 117 ===\n",
      "Step 91750\n",
      "Step 92000\n",
      "Step 92250\n",
      "Step 92500\n",
      "Mean Episode Loss: 2.5840 | Episode Reward: 7.9681 | Mean Reward: 10.9179\n",
      "Model has been training for 466.1854 minutes.\n",
      "=== Starting Episode 118 ===\n",
      "Step 92750\n",
      "Step 93000\n",
      "Step 93250\n",
      "Step 93500\n",
      "Mean Episode Loss: 7.2708 | Episode Reward: 13.5111 | Mean Reward: -14.7383\n",
      "Model has been training for 471.0385 minutes.\n",
      "=== Starting Episode 119 ===\n",
      "Step 93750\n",
      "Step 94000\n",
      "Step 94250\n",
      "Step 94500\n",
      "Mean Episode Loss: 3.3376 | Episode Reward: -4.9319 | Mean Reward: -14.9855\n",
      "Model has been training for 475.7452 minutes.\n",
      "=== Starting Episode 120 ===\n",
      "Step 94750\n",
      "Step 95000\n",
      "Step 95250\n",
      "Step 95500\n",
      "Mean Episode Loss: 1.4978 | Episode Reward: -1.5854 | Mean Reward: -6.0955\n",
      "Model has been training for 480.5202 minutes.\n",
      "=== Starting Episode 121 ===\n",
      "Step 95750\n",
      "Step 96000\n",
      "Step 96250\n",
      "Step 96500\n",
      "Mean Episode Loss: 1.4406 | Episode Reward: 3.0611 | Mean Reward: -6.5873\n",
      "Model has been training for 485.1881 minutes.\n",
      "=== Starting Episode 122 ===\n",
      "Step 96750\n",
      "Step 97000\n",
      "Step 97250\n",
      "Step 97500\n",
      "Mean Episode Loss: 1.4062 | Episode Reward: -3.0233 | Mean Reward: -7.0711\n",
      "Model has been training for 489.7536 minutes.\n",
      "=== Starting Episode 123 ===\n",
      "Step 97750\n",
      "Step 98000\n",
      "Step 98250\n",
      "Step 98500\n",
      "Mean Episode Loss: 0.1478 | Episode Reward: 9.0277 | Mean Reward: -7.3775\n",
      "Model has been training for 494.1295 minutes.\n",
      "=== Starting Episode 124 ===\n",
      "Step 98750\n",
      "Step 99000\n",
      "Step 99250\n",
      "Step 99500\n",
      "Mean Episode Loss: 0.1357 | Episode Reward: -1.0767 | Mean Reward: 2.9089\n",
      "Model has been training for 498.6915 minutes.\n",
      "=== Starting Episode 125 ===\n",
      "Step 99750\n",
      "Step 100000\n",
      "Step 100250\n",
      "Step 100500\n",
      "Mean Episode Loss: 0.6048 | Episode Reward: 184.3725 | Mean Reward: 21.4030\n",
      "Model has been training for 503.3945 minutes.\n",
      "=== Starting Episode 126 ===\n",
      "Mean Episode Loss: 0.1218 | Episode Reward: -95.6865 | Mean Reward: 11.1637\n",
      "Model has been training for 503.7099 minutes.\n",
      "=== Starting Episode 127 ===\n",
      "Step 100750\n",
      "Step 101000\n",
      "Step 101250\n",
      "Step 101500\n",
      "Mean Episode Loss: 1.1880 | Episode Reward: 1.0828 | Mean Reward: 10.4751\n",
      "Model has been training for 508.3485 minutes.\n",
      "=== Starting Episode 128 ===\n",
      "Step 101750\n",
      "Step 102000\n",
      "Step 102250\n",
      "Step 102500\n",
      "Mean Episode Loss: 4.3035 | Episode Reward: 14.1210 | Mean Reward: 10.5361\n",
      "Model has been training for 512.7384 minutes.\n",
      "=== Starting Episode 129 ===\n",
      "Step 102750\n",
      "Step 103000\n",
      "Step 103250\n",
      "Step 103500\n",
      "Mean Episode Loss: 2.3775 | Episode Reward: 0.3850 | Mean Reward: 11.0678\n",
      "Model has been training for 517.5017 minutes.\n",
      "=== Starting Episode 130 ===\n",
      "Step 103750\n",
      "Step 104000\n",
      "Step 104250\n",
      "Step 104500\n",
      "Mean Episode Loss: 7.0725 | Episode Reward: 3.5613 | Mean Reward: 11.5825\n",
      "Model has been training for 521.9842 minutes.\n",
      "=== Starting Episode 131 ===\n",
      "Mean Episode Loss: 0.3663 | Episode Reward: -100.0000 | Mean Reward: 1.2764\n",
      "Model has been training for 521.9959 minutes.\n",
      "=== Starting Episode 132 ===\n",
      "Step 104750\n",
      "Mean Episode Loss: 0.5410 | Episode Reward: -96.3857 | Mean Reward: -8.0599\n",
      "Model has been training for 522.9632 minutes.\n",
      "=== Starting Episode 133 ===\n",
      "Step 105000\n",
      "Step 105250\n",
      "Step 105500\n",
      "Mean Episode Loss: 9.2773 | Episode Reward: -137.5132 | Mean Reward: -22.7139\n",
      "Model has been training for 527.5206 minutes.\n",
      "=== Starting Episode 134 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Episode Loss: 0.2670 | Episode Reward: -99.1370 | Mean Reward: -32.5200\n",
      "Model has been training for 527.5964 minutes.\n",
      "=== Starting Episode 135 ===\n",
      "Step 105750\n",
      "Step 106000\n",
      "Step 106250\n",
      "Step 106500\n",
      "Mean Episode Loss: 7.7216 | Episode Reward: 7.9166 | Mean Reward: -50.1656\n",
      "Model has been training for 532.0082 minutes.\n",
      "=== Starting Episode 136 ===\n",
      "Step 106750\n",
      "Step 107000\n",
      "Step 107250\n",
      "Step 107500\n",
      "Mean Episode Loss: 9.9745 | Episode Reward: 8.6796 | Mean Reward: -39.7289\n",
      "Model has been training for 536.4213 minutes.\n",
      "=== Starting Episode 137 ===\n",
      "Step 107750\n",
      "Step 108000\n",
      "Step 108250\n",
      "Step 108500\n",
      "Mean Episode Loss: 8.2325 | Episode Reward: 8.3602 | Mean Reward: -39.0012\n",
      "Model has been training for 540.7837 minutes.\n",
      "=== Starting Episode 138 ===\n",
      "Step 108750\n",
      "Step 109000\n",
      "Step 109250\n",
      "Step 109500\n",
      "Mean Episode Loss: 6.0933 | Episode Reward: 5.4544 | Mean Reward: -39.8679\n",
      "Model has been training for 545.2116 minutes.\n",
      "=== Starting Episode 139 ===\n",
      "Step 109750\n",
      "Step 110000\n",
      "Step 110250\n",
      "Step 110500\n",
      "Mean Episode Loss: 14.5159 | Episode Reward: 186.7076 | Mean Reward: -21.2356\n",
      "Model has been training for 549.7086 minutes.\n",
      "=== Starting Episode 140 ===\n",
      "Step 110750\n",
      "Step 111000\n",
      "Step 111250\n",
      "Step 111500\n",
      "Mean Episode Loss: 5.8200 | Episode Reward: -2.2082 | Mean Reward: -21.8126\n",
      "Model has been training for 553.9787 minutes.\n",
      "=== Starting Episode 141 ===\n",
      "Step 111750\n",
      "Step 112000\n",
      "Step 112250\n",
      "Step 112500\n",
      "Mean Episode Loss: 7.6635 | Episode Reward: -88.6501 | Mean Reward: -20.6776\n",
      "Model has been training for 557.4925 minutes.\n",
      "=== Starting Episode 142 ===\n",
      "Step 112750\n",
      "Step 113000\n",
      "Step 113250\n",
      "Mean Episode Loss: 9.7742 | Episode Reward: -107.8875 | Mean Reward: -21.8277\n",
      "Model has been training for 561.5486 minutes.\n",
      "=== Starting Episode 143 ===\n",
      "Step 113500\n",
      "Step 113750\n",
      "Step 114000\n",
      "Step 114250\n",
      "Mean Episode Loss: 9.4642 | Episode Reward: 67.4008 | Mean Reward: -1.3363\n",
      "Model has been training for 565.8190 minutes.\n",
      "=== Starting Episode 144 ===\n",
      "Step 114500\n",
      "Step 114750\n",
      "Step 115000\n",
      "Step 115250\n",
      "Mean Episode Loss: 1.5522 | Episode Reward: -2.3040 | Mean Reward: 8.3470\n",
      "Model has been training for 570.0574 minutes.\n",
      "=== Starting Episode 145 ===\n",
      "Step 115500\n",
      "Mean Episode Loss: 16.3724 | Episode Reward: -94.6661 | Mean Reward: -1.9113\n",
      "Model has been training for 570.3887 minutes.\n",
      "=== Starting Episode 146 ===\n",
      "Step 115750\n",
      "Step 116000\n",
      "Step 116250\n",
      "Step 116500\n",
      "Mean Episode Loss: 6.9163 | Episode Reward: 1.9715 | Mean Reward: -2.5821\n",
      "Model has been training for 574.6200 minutes.\n",
      "=== Starting Episode 147 ===\n",
      "Step 116750\n",
      "Step 117000\n",
      "Step 117250\n",
      "Step 117500\n",
      "Mean Episode Loss: 5.3496 | Episode Reward: 0.0002 | Mean Reward: -3.4181\n",
      "Model has been training for 578.7921 minutes.\n",
      "=== Starting Episode 148 ===\n",
      "Step 117750\n",
      "Step 118000\n",
      "Step 118250\n",
      "Step 118500\n",
      "Mean Episode Loss: 5.9544 | Episode Reward: 150.3123 | Mean Reward: 11.0677\n",
      "Model has been training for 583.3530 minutes.\n",
      "=== Starting Episode 149 ===\n",
      "Step 118750\n",
      "Step 119000\n",
      "Step 119250\n"
     ]
    }
   ],
   "source": [
    "train_deepcnn_model(cnn_model, cnn_model_name, adversary_models, frame_skip=FRAME_SKIP, update_freq=UPDATE_FREQ,\n",
    "                    target_net_sync_freq=TARGET_NET_SYNC_FREQ, max_eps=MAX_EPS, max_steps_per_ep=MAX_STEPS_PER_EP,\n",
    "                    prefill_buffer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded training hyperparams\n",
    "FRAME_SKIP = 4\n",
    "UPDATE_FREQ = FRAME_SKIP\n",
    "TARGET_NET_SYNC_FREQ = 1000\n",
    "MAX_EPS = 250\n",
    "MAX_STEPS_PER_EP = 500\n",
    "\n",
    "# loaded CNN hyperparams\n",
    "TAU = 4\n",
    "GAMMA = 0.95\n",
    "EPS_START = 0.05\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY_WINDOW = 50\n",
    "REPLAY_BUF_CAPACITY = 10000\n",
    "REPLAY_BUF_PREFILL_AMT = 1000\n",
    "LR = 0.001\n",
    "DOWNSAMPLE_SIZE = (112, 112)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "loaded_model = DeepCNNModel(tau=TAU, gamma=GAMMA, eps_start=EPS_START, eps_end=EPS_END,\n",
    "                            eps_decay_window=EPS_DECAY_WINDOW, replay_buf_capacity=REPLAY_BUF_CAPACITY,\n",
    "                            replay_buf_prefill_amt=REPLAY_BUF_PREFILL_AMT, lr=LR,\n",
    "                            downsample_size=DOWNSAMPLE_SIZE, batch_size=BATCH_SIZE)\n",
    "loaded_model_name = 'dqn_loaded_next_250_step'\n",
    "loaded_model = fs.load_deep_cnn_from_device(loaded_model, 'dqn_cnn_500ep_v2', 'cpu')\n",
    "adversary_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_deepcnn_model(loaded_model, loaded_model_name, adversary_models, frame_skip=FRAME_SKIP, update_freq=UPDATE_FREQ,\n",
    "                    target_net_sync_freq=TARGET_NET_SYNC_FREQ, max_eps=MAX_EPS, max_steps_per_ep=MAX_STEPS_PER_EP,\n",
    "                    prefill_buffer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
